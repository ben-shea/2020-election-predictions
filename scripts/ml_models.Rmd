---
title: "Can we Predict the US Election?"
author: Ben Shea, Mukund Poddar, Nellie Ponarul and Saul Holding
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(e1071)
library(xgboost)
library(Metrics)
```


### Model Fitting

We will load our dataset here that has been cleaned and put together with all the scripts in the 'cleaning_scripts folder'. We will then standardise the data.

Note: many ML applications use the data from the training set only to standardise the test set. However, that is the general practice when real world examples come one at a time while the training has been performed on many more instance together. The assumption there is that the distribution of the data is uniform across the training and test examples. In our application, each election cycle is unique, and is processed together. Before a certain election year, all the counties' predictors would be collected and the predictions would be done as a batch. Hence, we can standardise data grouped by an election cycle.

```{r dataset, message = FALSE}
train = read_csv("../data/merged_final_2016.csv")
test = read_csv("../data/merged_final_2020.csv")
train = train[complete.cases(train),]
x_train = train[c(2:(length(train)-1))]
y_train = train[length(train)]
colnames(y_train) = 'actual'

test = test[complete.cases(test),]
x_test = test[c(2:(length(test)-1))]
y_test = test[length(test)]
colnames(y_test) = 'actual'

x_train = scale(x_train)
x_test = scale(x_test)
# col_means = apply(x_train, 2, mean)
# col_sds = apply(x_train, 2, sd)

# x_train = sweep(x_train, 2, col_means, FUN = "-")
# x_train = sweep(x_train, 2, col_sds, FUN = "/")
# x_test = sweep(x_test, 2, col_means, FUN = "-")
# x_test = sweep(x_test, 2, col_sds, FUN = "/")
```

We now start using different Machine Learning models to predict the election outcomes. To keep some standardisation, we will store the actual results, and the predictions from each of the models we use into the y_train and y_test dataframes created above.


#### Multiple Linear Regression  

We selected a subset of our covariates for this model using a backwards stepwise selection:
```{r mlr, eval = F}
# Set up data as dataframe for MLR
x_train_mlr <- x_train %>% data.frame() %>% bind_cols(y_train)
x_test_mlr <- x_test %>% data.frame() %>% bind_cols(y_test)
# Fit model with backwards selected variables
covs <- names(x_train)[-length(names(x_train))]
covs <- paste0(covs, collapse = " + ")

mlr_model <- lm(actual ~ popestimate + race_white + race_black + 
    race_hispanic + race_aac + age_0_to_19_years + age_20_to_39_years + 
    age_40_to_59_years + nonprofit + nondurable_goods + raw_gdp + 
    gdp_change + unemployment + dem_poll_median + dem_poll_sd + 
    rep_poll_mean + rep_poll_median + rep_poll_sd + consistency_dem, data = x_train_mlr)

test$mlr = predict(mlr_model, x_test_mlr)
```


#### Support Vector Machines  

This model creates a decision boundary between the classes being predicted using the datapoints on the edges of the class clusters. You can read more about SVMs on [wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine).
```{r svm, eval = F}
svm_model = svm(x=x_train, y=y_train)
test$svm = predict(svm_model, x_test)
```

#### XGBoost

This model is an optimized distributed gradient boosting library, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. [parameters](https://xgboost.readthedocs.io/en/latest/parameter.html)
```{r xgboost, eval = F}
train_final <- matrix(as.numeric(data.matrix(x_train)), nrow = nrow(train))
test_final <- matrix(as.numeric(data.matrix(x_test)), nrow = nrow(test))
#train_party_outcome <- ifelse(train_complete$democrats_pct>train_complete$republicans_pct,1,0)
train_party_outcome <- train$dem_rep_ratio
train_outcome <- matrix(as.numeric(data.matrix(train_party_outcome)))

# GRID SEARCH -------------------------------------------------------------------------------
#https://www.kaggle.com/silverstone1903/xgboost-grid-search-r

searchGridSubCol <- expand.grid(subsample = c(0.5,0.7,1), 
                                colsample_bytree = c(0.5,0.7,1),
                                max_depth = c(3,4,5,6),
                                eta = c(0.1,0.2,0.3,0.4)
)

obj<- "reg:squarederror"

weightsData <- scales::rescale(train$popestimate, to=c(0,1))

system.time(
  rmseErrorsHyperparameters <- apply(searchGridSubCol, 1, function(parameterList){
    
    #Extract Parameters to test
    currentSubsampleRate <- parameterList[["subsample"]]
    currentColsampleRate <- parameterList[["colsample_bytree"]]
    currentDepth <- parameterList[["max_depth"]]
    currentEta <- parameterList[["eta"]]
    currentMinChild <- 1
    xgb_model <- xgboost(data =  x_train, label=train_outcome, nrounds = 100, 
                         verbose = 0,"max.depth" = currentDepth, "eta" = currentEta,                               
                         "subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
                         , print_every_n = 20, "min_child_weight" = currentMinChild,
                         early_stopping_rounds = 10,objective=obj, eval_metric="rmse", #weights = weightsData
                         )
    
    xvalidationScores <- as.data.frame(xgb_model$evaluation_log)
    trmse <- tail(xvalidationScores$train_rmse,1)
    output <- return(c(trmse, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild))}))

output <- as.data.frame(t(rmseErrorsHyperparameters))
varnames <- c("TrainRMSE", "SubSampRate", "ColSampRate", "Depth","eta","currentMinChild")
names(output) <- varnames
head(output)
best_params <- output[which.min(output$TrainRMSE),]
best_params
# -----------------------------------------------------------------------------------------------

#https://xgboost.readthedocs.io/en/latest/parameter.html
xgb_model = xgboost(data=x_train, 
                    label=train_outcome, 
                    missing = NaN,
                    nrounds=100,
                    verbosity=1, 
                    eta=best_params$eta, 
                    max_depth=best_params$Depth, 
                    subsample=best_params$SubSampRate, 
                    min_child=best_params$currentMinChild,
                    colsample_bytree=best_params$ColSampRate,
                    objective=obj, 
                    eval_metric="rmse"
                    #,weights = weightsData
                    )

# train_preds <- predict(xgb_model, x_train, missing = NaN)
# rmse(train$dem_rep_ratio,train_preds)
# plot(train$dem_rep_ratio,train_preds)

# test_preds <- predict(xgb_model, x_test, missing = NaN)
test$xgb <- predict(xgb_model, test_final, missing = NaN)
xgboost_rmse <- rmse(test$dem_rep_ratio,test_preds)
# plot(test$dem_rep_ratio,test_preds)
```  

```{r, echo = F}
# Save out predictions so we don't run code multiple times
# save(mlr_model, svm_model, xgb_model, test, file = "../data/raw_predictions.rda")
load("../data/raw_predictions.rda")
```

 

### Outcomes

#### Predict Electoral College Split

```{r}
# electoral college
elect_tbl <- read_csv("../data/electoral_college.csv")
maine_neb <- read_csv("../data/electoral_votes_main_nebraska.csv")

# Actual results 2020
elect_tbl_actual_2020 <- read_csv("../data/electoral_college_actual_2020.csv")
maine_neb_actual_2020 <- read_csv("../data/electoral_votes_main_nebraska_actual_2020.csv")
#read in county/state crosswalk
base_county_state_fips <- read_csv("../data/Clean Data/base_county_state_fips_lkp.csv")

# Function to take a prediction and calculate electoral college split
get_electoral_college <- function(df, pred_input, elect_votes =  elect_tbl, maine_neb_elect = maine_neb){
  # roll up to State level 
  test_pred_df <- data.frame(fips = df$fips, 
                             dem_rep_ratio = df[pred_input],
                           pop_estimate = df$popestimate)
  
  names(test_pred_df) <- c("fips", "dem_rep_ratio", "pop_estimate")
    test_pred_df <- test_pred_df %>%
    mutate(
      dem_rep_ratio_votes = dem_rep_ratio*pop_estimate,
      state_fips = str_sub(fips, 1,2)
    ) %>%
    left_join(
      base_county_state_fips[c("stname","fips")], 
      by="fips")
  
  #most of electoral college
  elect_rollup <- test_pred_df %>% 
    left_join(
      elect_tbl, 
      by = c("stname" ="state")) %>% 
    group_by(state_fips, stname) %>% 
    summarize(total_dem_rep_ratio_votes = sum(dem_rep_ratio_votes),
              total_pop = sum(pop_estimate)) %>%
    mutate(
      state_win=ifelse(total_dem_rep_ratio_votes>total_pop,1,0)
      )
  
  final_elect_rollup <- elect_rollup %>% 
  left_join(elect_votes %>% 
              select(state, elect_votes), 
            by=c("stname" ="state")) %>%
  mutate(
    dem_electoral_votes = state_win*elect_votes,
    rep_electoral_votes = elect_votes - dem_electoral_votes
    )
  
  # Additional Maine/Nebraska Calculation
  #maine and nebraska
  maine_neb_elect$fips <- as.character(maine_neb_elect$fips)
  elect_rollup_mn <- maine_neb_elect %>% left_join(test_pred_df, by = c("fips","state"="stname"))
  elect_rollup_mn <- elect_rollup_mn[complete.cases(elect_rollup_mn), ] %>% 
    group_by(state,congress_district) %>% summarize(total_dem_rep_ratio_votes = sum(dem_rep_ratio_votes),
                                              total_pop = sum(pop_estimate)) %>%
    mutate(state_win=ifelse(as.numeric(total_dem_rep_ratio_votes)>as.numeric(total_pop),1,0))
  
  final_elect_rollup_mn <- elect_rollup_mn %>% 
  mutate(dem_electoral_votes = state_win,rep_electoral_votes = 1-dem_electoral_votes)
  
  # add up the Maine Nebraska state totals and then add them to the final rollup
  final_elect_rollup <- final_elect_rollup %>% 
    left_join(
      final_elect_rollup_mn %>% 
        group_by(state) %>% 
        summarize(
          total_dem_rep_ratio_votes = sum(total_dem_rep_ratio_votes),
          total_pop = sum(total_pop),
          dem_electoral_votes = sum(dem_electoral_votes),
          rep_electoral_votes = sum(rep_electoral_votes),
        ),
      by = c("stname" = "state"),
      suffix = c("", "_mn")
    ) %>% 
    mutate(
      total_dem_rep_ratio_votes = ifelse(!is.na(total_dem_rep_ratio_votes_mn), total_dem_rep_ratio_votes + total_dem_rep_ratio_votes_mn, total_dem_rep_ratio_votes),
      total_pop = ifelse(!is.na(total_pop_mn), total_pop + total_pop_mn, total_pop),
      dem_electoral_votes = ifelse(!is.na(dem_electoral_votes_mn), dem_electoral_votes + dem_electoral_votes_mn, dem_electoral_votes),
      rep_electoral_votes = ifelse(!is.na(rep_electoral_votes_mn), rep_electoral_votes + rep_electoral_votes_mn, rep_electoral_votes),
    ) %>% 
    select(names(.)[!str_detect(names(.), "_mn")])
  
  # Check state win for Main and Nebraska (set it to 0 since these are not winner-take-all states)
  
  # final_elect_rollup$state_win[final_elect_rollup$stname %in% c("Maine", "Nebraska")] <- 0
  
  
  return(final_elect_rollup)
    
}


electoral_college_predictions <- map(.x = list("mlr", "svm", "xgb"), .f = ~get_electoral_college(test, .x)) %>% setNames(list("mlr", "svm", "xgb"))

# Synthesize actual outcomes and add them to the list
  actual_results <- bind_rows(
    elect_tbl_actual_2020 %>% 
      mutate(
        dem_electoral_votes = state_win*elect_votes,
        rep_electoral_votes = elect_votes - dem_electoral_votes
      ),
    maine_neb_actual_2020 %>% 
      distinct(state_fips, state, congress_district, state_win) %>% 
      mutate(
        dem_electoral_votes = 1*state_win, 
        rep_electoral_votes = 1 - dem_electoral_votes
        ) %>% 
      group_by(state_fips, state, state_win) %>% 
      summarize(
        dem_electoral_votes = sum(dem_electoral_votes), 
        rep_electoral_votes = sum(rep_electoral_votes)) %>% 
      rename(fips = state_fips)
    )

  actual_results <- actual_results %>% 
    group_by(fips, state) %>% 
    summarize(
      dem_electoral_votes = sum(dem_electoral_votes), 
      rep_electoral_votes = sum(rep_electoral_votes),
      state_win = max(state_win, na.rm = T)
    ) %>% 
    rename(
      state_fips = fips,
      stname = state
    )
  
  # Fix nebraska state win
  actual_results[actual_results$stname == "Nebraska", ]$state_win <- 0
  
  electoral_college_predictions[["actual"]] <- actual_results
  
# Save out predictions for Shiny app
saveRDS(electoral_college_predictions, "../data/electoral_college_predictions.rds")



```


### Error Metrics  

We want to now look at the metrics for all the models used. For now we just visualise the predictions against the actual outcomes, and we will fill more here in due time.


```{r visualisation}
# will correct aspect ratio
ggplot(test, aes(x=dem_rep_ratio)) + geom_point(aes(y=svm)) + geom_abline(slope=1, intercept = 0, color='red') +ylim(c(0,1))

test %>% 
  select(dem_rep_ratio, mlr, svm, xgb) %>% 
  gather(pred_type, value, -dem_rep_ratio) %>% 
  ggplot(aes(x = dem_rep_ratio, y = value, color = pred_type)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0) +
  scale_color_manual(name = "Prediction\nType", values = c("darkolivegreen3", "darkorange3", "dodgerblue3")) +
  theme_bw() +
  xlab("Actual Values") +
  ylab("Predictions") +
  ggtitle("Plot of predictions against actual values\n(Ratio of Democrat to Republican Votes)")
  
```  
```{r rmse}
# Create a data frame of all root MSEs
data.frame(
  Models = c("Multiple Linear Regression", "Support Vector Machine", "XGBoost"),
  `Root MSE` = c(sqrt(mean(mlr_model$residuals^2)), 
           sqrt(mean(svm_model$residuals^2)),
           rmse(test$dem_rep_ratio,predict(xgb_model, x_test, missing = NaN)))
) %>% kableExtra::kable() %>% kableExtra::kable_styling()


```


